{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import *\n",
    "from data import IAMDataset\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"../../datasets/iam\"\n",
    "# Number of workers for dataloader\n",
    "workers = 5\n",
    "# Batch size during training\n",
    "batch_size = 8\n",
    "# Spatial size of training images.\n",
    "imsize=(64,640)\n",
    "# Number of training epochs\n",
    "num_epochs = 1\n",
    "# Max word len\n",
    "min_len = 2\n",
    "max_len=10\n",
    "# Chars and <end>\n",
    "vocab_size=27\n",
    "\n",
    "# Create the dataset\n",
    "dataset = IAMDataset(data_path=dataroot, imsize=imsize, min_len=min_len, max_len=max_len)\n",
    "dataset_words = dataset.create_word_dataset()\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True, num_workers=workers)\n",
    "dataloader_words = torch.utils.data.DataLoader(dataset_words, batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "# Initialize Generator H\n",
    "generator = GANwritingGenerator(imsize, max_len).cuda()\n",
    "\n",
    "# Initialize Discriminators\n",
    "discriminator = Discriminator(num_classes=1, imsize=imsize).cuda()\n",
    "writer_classifier = Discriminator(num_classes=dataset.num_writers, imsize=imsize).cuda()\n",
    "word_recognizer = Seq2Seq(imsize=imsize, max_len=max_len+1, vocab_size=vocab_size).cuda()\n",
    "\n",
    "# Initialize BCELoss function\n",
    "criterion_binary = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion_KLDiv = nn.KLDivLoss(reduction='mean')\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "REAL = 1\n",
    "FAKE = 0\n",
    "\n",
    "# Setup Adam optimizers for both D and W\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizerWC = optim.Adam(writer_classifier.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizerWR = optim.Adam(word_recognizer.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "# Turn on/off training stages\n",
    "train_D = True\n",
    "train_WC = True\n",
    "train_WR = True\n",
    "train_G = True\n",
    "\n",
    "# Init output tensors\n",
    "lossD = torch.tensor([0])\n",
    "lossWC = torch.tensor([0])\n",
    "lossWR = torch.tensor([0])\n",
    "lossG = torch.tensor([0])\n",
    "D_x = torch.tensor([0])\n",
    "D_G_z1 = torch.tensor([0])\n",
    "D_G_z2 = torch.tensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "D_losses = []\n",
    "WC_losses = []\n",
    "WR_losses = []\n",
    "G_losses = []\n",
    "iters = 0\n",
    "\n",
    "# for Seq2Seq\n",
    "src_len = imsize[1] * torch.ones(batch_size)\n",
    "\n",
    "# fixed input to track progress\n",
    "styles_fixed, _, _ = dataset[500]\n",
    "styles_fixed = styles_fixed[None,...]\n",
    "# content_fixed = dataset_words[5][None,...]\n",
    "content_fixed = torch.zeros(1, max_len, dtype=int)\n",
    "content_fixed[0,:6] = torch.tensor([list(map(lambda x: ord(x) - ord('a'), \"vision\"))])\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, ((styles, content_real, writer_id), content_new) in enumerate(zip(dataloader, dataloader_words)):\n",
    "        styles = styles.cuda() # sample - 15 images concatenated channel-wise\n",
    "        images_real = styles[:,0:1,:,:] # take 1 image per sample\n",
    "        writer_id = writer_id.cuda()\n",
    "        content_real = content_real[:,0,:].cuda()\n",
    "        content_new = content_new.cuda()\n",
    "        content_real_one_hot = F.one_hot(content_real, num_classes=vocab_size).float()\n",
    "        content_new_one_hot = F.one_hot(content_new, num_classes=vocab_size).float()\n",
    "        \n",
    "        # Generate fake images\n",
    "        images_fake = generator(styles, content_new)\n",
    "        \n",
    "        ############################\n",
    "        # Update D networks: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        # (1) Discriminative loss on fake&real images (discriminator)\n",
    "        if train_D:\n",
    "            discriminator.zero_grad()\n",
    "\n",
    "            outD_real = discriminator(images_real).view(-1)\n",
    "            label = torch.full((batch_size,), REAL, dtype=torch.float, device=\"cuda\")\n",
    "            loss_real = criterion_binary(outD_real, label)\n",
    "\n",
    "            outD_fake = discriminator(images_fake.detach()).view(-1)\n",
    "            label = torch.full((batch_size,), FAKE, dtype=torch.float, device=\"cuda\")\n",
    "            loss_fake = criterion_binary(outD_fake, label)\n",
    "\n",
    "            lossD = loss_fake + loss_real\n",
    "            lossD.backward()\n",
    "            optimizerD.step() # Update D\n",
    "\n",
    "            D_x = outD_real.mean().item()\n",
    "            D_G_z1 = outD_fake.mean().item()\n",
    "\n",
    "        # (2) Style loss on real data (writer classifier)\n",
    "        if train_WC:\n",
    "            writer_classifier.zero_grad()\n",
    "\n",
    "            outWC_real = writer_classifier(images_real)\n",
    "            lossWC = criterion(outWC_real, writer_id)\n",
    "            lossWC.backward()\n",
    "            optimizerWC.step() # Update WC\n",
    "\n",
    "        # (3) Content loss on real data (word recognizer)\n",
    "        if train_WR:\n",
    "            word_recognizer.zero_grad()\n",
    "\n",
    "            outWR_real, _ = word_recognizer(images_real, content_real_one_hot, src_len)\n",
    "            outWR_real = outWR_real.transpose(0,1)\n",
    "            lossWR = criterion_KLDiv(F.log_softmax(outWR_real, dim=2), content_real_one_hot)\n",
    "            lossWR.backward()\n",
    "            optimizerWR.step()\n",
    "        \n",
    "        ############################\n",
    "        # Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        \n",
    "        if train_G:\n",
    "            # Complete loss on fake data\n",
    "            generator.zero_grad()\n",
    "\n",
    "            # Since we just updated D, perform another forward passes\n",
    "            outD_fake = discriminator(images_fake).view(-1)\n",
    "            # fake labels are real for generator cost:\n",
    "            label = torch.full((batch_size,), REAL, dtype=torch.float, device=\"cuda\") \n",
    "            lossG = criterion_binary(outD_fake, label)\n",
    "\n",
    "            if train_WC:\n",
    "                outWC_fake = writer_classifier(images_fake)\n",
    "                lossG_WC = criterion(outWC_fake, writer_id)\n",
    "                lossG = lossG + lossG_WC\n",
    "\n",
    "            if train_WR:\n",
    "                outWR_fake, _ = word_recognizer(images_fake, content_new_one_hot, src_len)\n",
    "                outWR_fake = outWR_fake.transpose(0,1)\n",
    "                lossG_WR = criterion_KLDiv(F.log_softmax(outWR_fake, dim=2), content_new_one_hot)\n",
    "                lossG = lossG + lossG_WR\n",
    "\n",
    "            lossG.backward()\n",
    "            optimizerG.step() # Update G\n",
    "\n",
    "            D_G_z2 = outD_fake.mean().item()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 10 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss[D,WC,WR]: %.4f\\t%.4f\\t%.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     lossD.item(), lossWC.item(), lossWR.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        D_losses.append(lossD.item())\n",
    "        WC_losses.append(lossWC.item())\n",
    "        WR_losses.append(lossWR.item())\n",
    "        G_losses.append(lossG.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 50 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                generator.eval()\n",
    "                fake = generator(styles_fixed.cuda(), content_fixed.cuda()).detach().cpu()[0].permute(1,2,0)\n",
    "                generator.train()\n",
    "            img_list.append(fake)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot losses\n",
    "# plt.figure(figsize=(16,16))\n",
    "# plt.title(\"Test Images\")\n",
    "# plt.plot(D_losses, label='D')\n",
    "# plt.plot(WC_losses, label='WC')\n",
    "# plt.plot(WR_losses, label='WR')\n",
    "# plt.plot(G_losses, label='G')\n",
    "# plt.yscale('log')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x-x.min())/(x.max()-x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Plot some generated images\n",
    "\n",
    "# plt.figure(figsize=(16,160))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Test Images\")\n",
    "# # plt.imshow(torch.cat([normalize(x) for x in img_list], dim=0).repeat(1,1,3))\n",
    "# I = np.transpose(torch.stack([normalize(x) for x in img_list]), (0,3,1,2))\n",
    "# I = np.transpose(vutils.make_grid(I, nrow=1, padding=4, normalize=True).cpu(),(1,2,0))\n",
    "# plt.imshow(I)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot some training images\n",
    "\n",
    "# real_batch, _, _ = next(iter(dataloader))\n",
    "# plt.figure(figsize=(16,16))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[:,0:1,:,:].repeat(1,3,1,1), nrow=1, padding=4, normalize=True).cpu(),(1,2,0)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save images\n",
    "\n",
    "# for i,im in enumerate(img_list):\n",
    "#     A = normalize(im.repeat(1,1,3).numpy())\n",
    "#     plt.figure(figsize=(12,12))\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(A)\n",
    "#     plt.savefig(\"./res/\" + str(i) + \".jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
